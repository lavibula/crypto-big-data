{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "keyfile_path = \"btcanalysishust-b10a2ef12088.json\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaConsumer\") \\\n",
    "  .config(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.auth.type\", \"OAuth2\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.project.id\", \"btcanalysishust\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.input.close.input.streams.after.task.complete\", \"true\") \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", keyfile_path) \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu từ Kafka\n",
    "df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"35.206.252.44:9092\") \\\n",
    "    .option(\"subscribe\", \"crypto-prices\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "# Kafka data có các cột \"key\" và \"value\" dưới dạng binary\n",
    "df = df.selectExpr(\"CAST(value AS STRING) as value\")\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "\n",
    "schema_log = StructType([\n",
    "    StructField(\"timestamp\", StringType()),\n",
    "    StructField(\"prices\", StructType([\n",
    "        StructField(\"bitcoin\", FloatType()),\n",
    "        StructField(\"ethereum\", FloatType()),\n",
    "        StructField(\"tether\", FloatType()),\n",
    "        StructField(\"binancecoin\", FloatType()),\n",
    "        StructField(\"usd-coin\", FloatType()),\n",
    "        StructField(\"ripple\", FloatType()),\n",
    "        StructField(\"cardano\", FloatType()),\n",
    "        StructField(\"dogecoin\", FloatType()),\n",
    "        StructField(\"matic-network\", FloatType()),\n",
    "        StructField(\"solana\", FloatType()),        \n",
    "    ]))\n",
    "])\n",
    "\n",
    "from pyspark.sql.functions import col, from_json, explode, udf\n",
    "\n",
    "crypto_parsed_df = df.select(from_json(col(\"value\"), schema_log).alias(\"data\"))\n",
    "\n",
    "\n",
    "crypto_parsed_df = crypto_parsed_df.select(\n",
    "    col(\"data.timestamp\").alias(\"timestamp\"),\n",
    "    col(\"data.prices.bitcoin\").alias(\"BTC\"),\n",
    "    col(\"data.prices.ethereum\").alias(\"ETH\"),\n",
    "    col(\"data.prices.tether\").alias(\"TETHER\"),\n",
    "    col(\"data.prices.binancecoin\").alias(\"BNB\"),\n",
    "    col(\"data.prices.usd-coin\").alias(\"USDC\"),\n",
    "    col(\"data.prices.ripple\").alias(\"XRP\"),\n",
    "    col(\"data.prices.cardano\").alias(\"ADA\"),\n",
    "    col(\"data.prices.dogecoin\").alias(\"DOGE\"),\n",
    "    col(\"data.prices.matic-network\").alias(\"MATIC\"),\n",
    "    col(\"data.prices.solana\").alias(\"SOLANA\")\n",
    ")\n",
    "\n",
    "\n",
    "# Hiển thị dữ liệu đọc được ra console (cho thử nghiệm), không cắt ngắn các giá trị\n",
    "crypto_parsed_df.writeStream.format(\"console\").option(\"truncate\", \"false\").start().awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import to_date, col\n",
    "from dateutil.relativedelta import relativedelta\n",
    "def get_last_saved_date(crypto_id, storage_path : str):\n",
    "    \"\"\"\n",
    "    Kiểm tra ngày cuối cùng đã được lưu trữ trong GCS hoặc HDFS.\n",
    "    \"\"\"\n",
    "    storage_client = storage.Client.from_service_account_json(\"btcanalysishust-b10a2ef12088.json\")\n",
    "    blobs = storage_client.list_blobs(storage_path, prefix=f\"ver2/{crypto_id}/\")\n",
    "    last_saved_date = None\n",
    "    for blob in blobs:\n",
    "        # Trích xuất ngày từ tên thư mục\n",
    "        path_parts = blob.name.split('/')\n",
    "\n",
    "        if len(path_parts) > 2: \n",
    "            year, month = path_parts[2], path_parts[3]\n",
    "            date = datetime.strptime(f\"{year}-{month.zfill(2)}\",\"%Y-%m\")\n",
    "            if last_saved_date is None or date > last_saved_date:\n",
    "                last_saved_date = date\n",
    "\n",
    "    return last_saved_date.strftime(\"%Y-%m\")\n",
    "\n",
    "def get_gcs_price(crypto_id : str, start_date : str , end_date : str):\n",
    "    \"\"\"\n",
    "    Lấy dữ liệu giá từ GCS trong khoảng thời gian chỉ định và hợp nhất thành một bảng Spark.\n",
    "\n",
    "    Args:\n",
    "        crypto_id (str): Tên tài sản (crypto, cổ phiếu, v.v.).\n",
    "        start_date (str): Ngày bắt đầu (định dạng 'YYYY-MM').\n",
    "        end_date (str): Ngày kết thúc (định dạng 'YYYY-MM').\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Bảng Spark chứa tất cả dữ liệu giá hợp nhất.\n",
    "    \"\"\"\n",
    "    # Chuyển đổi chuỗi ngày thành đối tượng datetime\n",
    "    start = datetime.strptime(start_date, \"%Y-%m\")\n",
    "    end = datetime.strptime(end_date, \"%Y-%m\")\n",
    "    \n",
    "    # Kiểm tra ngày bắt đầu phải nhỏ hơn hoặc bằng ngày kết thúc\n",
    "    if start > end:\n",
    "        raise ValueError(\"start_date phải nhỏ hơn hoặc bằng end_date\")\n",
    "    \n",
    "    # Khởi tạo danh sách kết quả\n",
    "    all_prices = []\n",
    "    \n",
    "    # Lặp qua từng tháng\n",
    "    current = start.replace(day=1)  # Đặt ngày thành ngày đầu tiên của tháng\n",
    "    while current <= end:\n",
    "        curr_price_dir=f\"gs://crypto-historical-data-2/ver2/{crypto_id}/{current.year}/{current.month:02}/data.parquet\"\n",
    "        all_prices.append(spark.read.parquet(curr_price_dir))\n",
    "        if current.month == 12:  # Nếu là tháng 12, chuyển sang tháng 1 năm sau\n",
    "            current = current.replace(year=current.year + 1, month=1)\n",
    "        else:\n",
    "            current = current.replace(month=current.month + 1)\n",
    "    if all_prices:\n",
    "        merged_data = all_prices[0]\n",
    "        for df in all_prices[1:]:\n",
    "            merged_data = merged_data.union(df)\n",
    "        merged_data = merged_data.withColumn('DATE', to_date('DATE', 'yyyy-MM-dd'))\n",
    "        # Sort by the transformed date column\n",
    "        sorted_data = merged_data.orderBy('DATE', ascending= True)\n",
    "\n",
    "        # Sort the DataFrame by the date column\n",
    "        return sorted_data.select(col('DATE'),col('HIGH'),col('LOW'),col('CLOSE'))\n",
    "    else:\n",
    "        raise ValueError(\"Không tìm thấy dữ liệu trong khoảng thời gian được chỉ định.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'%K': 56.3851687986003, '%D': 78.55468205756692}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, max as spark_max, min as spark_min, avg\n",
    "from pyspark.sql.window import Window\n",
    "class STOCK:\n",
    "    def __init__(self, period_k=9, period_d=6, storage_path='crypto-historical-data-2' ):\n",
    "        self.k=period_k\n",
    "        self.d=period_d\n",
    "        self.storage_path=storage_path\n",
    "    def get_data(self,crypto_id):\n",
    "        lastest_month=get_last_saved_date(crypto_id,self.storage_path)\n",
    "        comeback_month=(self.k+self.d-1)//28+1\n",
    "        start_month=datetime.strptime(lastest_month,'%Y-%m')-relativedelta(months=comeback_month)\n",
    "        historical_data_df=get_gcs_price(crypto_id,start_month.strftime('%Y-%m'), lastest_month)\n",
    "        # gia tri gia su\n",
    "        current_close=95285.96\n",
    "        timestap='2024-11-26'\n",
    "        \n",
    "        current_close_df = spark.createDataFrame([(current_close,current_close,current_close, timestap)], [\"CLOSE\",'HIGH',\"LOW\",'DATE'])\n",
    "        combined_data_df = historical_data_df.unionByName(current_close_df,allowMissingColumns=True)\n",
    "        return spark.createDataFrame(combined_data_df.tail(self.k+self.d-1))\n",
    "    def calculate(self, crypto_id):\n",
    "        combined_data_df=self.get_data(crypto_id)\n",
    "        # Kiểm tra cột HIGH và LOW\n",
    "        if not {'HIGH', 'LOW'}.issubset(combined_data_df.columns):\n",
    "            raise ValueError(\"Dữ liệu thiếu cột HIGH hoặc LOW.\")\n",
    "        window_k = Window.orderBy(\"DATE\").rowsBetween(-(self.k - 1), 0)\n",
    "        combined_data_df = combined_data_df.withColumn(f\"HIGH_{self.k}\", spark_max(\"HIGH\").over(window_k))\n",
    "        combined_data_df = combined_data_df.withColumn(f\"LOW_{self.k}\", spark_min(\"LOW\").over(window_k))\n",
    "\n",
    "        # Tính %K\n",
    "        combined_data_df = combined_data_df.withColumn(\n",
    "            \"%K\", \n",
    "            100 * (col(\"CLOSE\") - col(f\"LOW_{self.k}\")) / (col(f\"HIGH_{self.k}\") - col(f\"LOW_{self.k}\"))\n",
    "        ).fillna(0, subset=[\"%K\"])  # Thay NaN bằng 0 nếu (HIGH_k - LOW_k) = 0.\n",
    "        \n",
    "        # Sử dụng cửa sổ để tính trung bình động cho %D\n",
    "        window_d = Window.orderBy(\"DATE\").rowsBetween(-(self.d - 1), 0)\n",
    "        combined_data_df = combined_data_df.withColumn(\"%D\", avg(\"%K\").over(window_d))\n",
    "        \n",
    "        # Trả về DataFrame với %K và %D\n",
    "        return combined_data_df.select( \"%K\", \"%D\").tail(1)[0].asDict()\n",
    "    def calculate__for_all(self,crypto_ids):\n",
    "        all_stocks={}\n",
    "        for crypto_id in crypto_ids:\n",
    "            all_stocks[crypto_id] = self.calculate(crypto_id)\n",
    "        return all_stocks\n",
    "cal_stock=STOCK()\n",
    "df=cal_stock.calculate('BTC')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MACD:\n",
    "    def __init__(self, phien_1, phien_2, storage_path ='crypto-historical-data-2') -> None:\n",
    "        self.phien_1=phien_1\n",
    "        self.phien_2=phien_2\n",
    "        self.storage_path=storage_path\n",
    "    def get_data(self, crypto_id):\n",
    "        ema_dir=f'{crypto_id}'\n",
    "        ema_phien1, ema_phien2=spark.read.parquet(ema_dir)\n",
    "        return ema_phien1,ema_phien2\n",
    "    def calculate(self, crypto_id):\n",
    "        ema_phien1,ema_phien2=self.get_data(crypto_id)\n",
    "        return ema_phien1-ema_phien2\n",
    "    def calculate__for_all(self,crypto_ids):\n",
    "        all_stocks={}\n",
    "        for crypto_id in crypto_ids:\n",
    "            all_stocks[crypto_id] = self.calculate(crypto_id)\n",
    "        return all_stocks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
